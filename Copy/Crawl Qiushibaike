# 糗事百科网络爬虫实战
import urllib.request
import re

headers = {}
headers['User-Agent'] = 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.140 Safari/537.36'
headers['Host'] = 'www.qiushibaike.com'

headall = []
for key, value in headers.items():
	item = (key, value)
	headall.append(item)

opener = urllib.request.build_opener()
opener.addheaders = headall
urllib.request.install_opener(opener)

for i in range(0,3):
	try:
		urln = 'https://www.qiushibaike.com/8hr/page/'+str(i+1)+'/'
		print('正在爬取'+str(i+1)+"页")

		req = urllib.request.Request(urln)
		data = urllib.request.urlopen(req).read().decode("utf-8","ignore")

		user_pat = '<h2>(.*?)</h2>'
		content_pat = '<div class="content">.*?<span>(.*?)</span>'
# .*?不加括号代表仅匹配，不提取

		user_data = re.compile(user_pat,re.S).findall(data)
		content_data = re.compile(content_pat,re.S).findall(data)
	
		for j in range(0, len(content_data)):
			print('正在爬取'+str(j)+"个contentdata")
			print(content_data[j])

	except Exception as err:
		print("异常的类型是:%s"%type(err))
		print("异常对象的内容是:%s"%err)
